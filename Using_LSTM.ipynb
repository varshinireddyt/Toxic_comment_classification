{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n",
      "/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n",
      "/kaggle/input/glove6b/glove.6B.300d.txt\n",
      "/kaggle/input/glove6b/glove.6B.100d.txt\n",
      "/kaggle/input/glove6b/glove.6B.50d.txt\n",
      "/kaggle/input/glove6b/glove.6B.200d.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20000\n",
    "max_length = 120\n",
    "embedding_dim = 50\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = \"<OOV>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\")\n",
    "test = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "comment_text     0\n",
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "comment_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#### Slicing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
       "       \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n",
       "       \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\",\n",
       "       ...,\n",
       "       'Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.',\n",
       "       'And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.',\n",
       "       '\"\\nAnd ... I really don\\'t think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train[label].values\n",
    "test_list = test[\"comment_text\"].fillna(\"_na_\").values\n",
    "train_sentences = train[\"comment_text\"].fillna(\"_na_\").values\n",
    "train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size,oov_token= oov_tok)\n",
    "tokenizer.fit_on_texts(list(train_sentences))\n",
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sequences:  47\n",
      "train padded:  120\n",
      "18\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "train_padded = pad_sequences(train_sequences,padding=padding_type,maxlen = max_length)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_list)\n",
    "test_padded = pad_sequences(test_sequences, padding = padding_type,maxlen = max_length)\n",
    "print(\"train sequences: \",len(train_sequences[0]))\n",
    "print(\"train padded: \",len(train_padded[0]))\n",
    "\n",
    "print(len(train_sequences[1]))\n",
    "print(len(train_padded[1]))\n",
    "\n",
    "# print(len(train_sequences[10]))\n",
    "# print(len(train_padded[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 120, 50)           1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 120, 100)          40400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 1,045,756\n",
      "Trainable params: 1,045,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# inp = Input(shape=(maxlen,))\n",
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Embedding(vocab_size,embedding_dim,input_length=max_length),\n",
    "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50,return_sequences=True)),\n",
    "tf.keras.layers.GlobalMaxPooling1D(),\n",
    "tf.keras.layers.Dense(50,activation='relu'),\n",
    "tf.keras.layers.Dense(6,activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 120)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples\n",
      "Epoch 1/5\n",
      "159571/159571 [==============================] - 120s 754us/sample - loss: 0.0616 - accuracy: 0.9794\n",
      "Epoch 2/5\n",
      "159571/159571 [==============================] - 115s 720us/sample - loss: 0.0442 - accuracy: 0.9834\n",
      "Epoch 3/5\n",
      "133920/159571 [========================>.....] - ETA: 17s - loss: 0.0385 - accuracy: 0.9852"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "history = model.fit(train_padded,y,epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 - 27s\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict([test_padded],verbose=2)\n",
    "sample_submission = pd.read_csv(\"/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\")\n",
    "sample_submission[label] = test_pred\n",
    "sample_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
